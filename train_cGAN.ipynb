{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "platform.python_version(): 3.9.18\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(f\"platform.python_version(): {platform.python_version()}\")\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rc('font', family='Microsoft JhengHei')\n",
    "\n",
    "# 檢查CUDA是否可用\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(npy_file_list): <class 'list'>\n",
      "len(npy_file_list): 35287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 24035/35287 [00:04<00:01, 5882.13it/s]"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "#載入mfcc為data\n",
    "npy_file_list = glob(f\"{os.getcwd()}\\\\mfcc\\\\*.npy\")\n",
    "print(f\"type(npy_file_list): {type(npy_file_list)}\")\n",
    "print(f\"len(npy_file_list): {len(npy_file_list)}\")\n",
    "\n",
    "mfcc_list = []\n",
    "\n",
    "for npy_file in tqdm(npy_file_list):\n",
    "    mfcc = np.load(file=npy_file)\n",
    "    mfcc_list.append(mfcc)\n",
    "\n",
    "mfcc_list = np.array(mfcc_list)\n",
    "print(f\"type(mfcc_list): {type(mfcc_list)}\")\n",
    "print(f\"mfcc_list.shape: {mfcc_list.shape}\")\n",
    "\n",
    "all_mfcc = []\n",
    "for mfcc in mfcc_list:\n",
    "    all_mfcc.append(mfcc)\n",
    "\n",
    "data = np.array(all_mfcc)\n",
    "data_len = len(data)\n",
    "#######################################################################\n",
    "\n",
    "#######################################################################\n",
    "#載入labelByself為labels\n",
    "load_data = np.load('labelByself.npz')\n",
    "labels = load_data['data']\n",
    "#######################################################################\n",
    "\n",
    "every_epoch = [] \n",
    "every_d_loss = []\n",
    "every_g_loss = []\n",
    "every_DZ = []\n",
    "\n",
    "class PhonemeDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "class ConditionalGenerator(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_shape, num_classes):\n",
    "        super(ConditionalGenerator, self).__init__()\n",
    "        self.output_shape = output_shape\n",
    "        self.output_dim = output_shape[0] * output_shape[1]\n",
    "        self.label_embedding = nn.Embedding(num_classes, input_dim)  # 將類別標籤轉換為與 z 相同維度的向量\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim * 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "            nn.BatchNorm1d(hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim * 4), \n",
    "            nn.BatchNorm1d(hidden_dim * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim * 4, self.output_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z, labels):\n",
    "        label_embedding = self.label_embedding(labels)\n",
    "        input_data = torch.cat([z, label_embedding], dim=1)  # 將噪聲 z 與條件 labels 拼接\n",
    "        x = self.model(input_data)\n",
    "        return x.view(x.size(0), *self.output_shape)\n",
    "\n",
    "\n",
    "class ConditionalDiscriminator(nn.Module):\n",
    "    def __init__(self, input_shape, hidden_dim, num_classes):\n",
    "        super(ConditionalDiscriminator, self).__init__()\n",
    "        self.input_dim = input_shape[0] * input_shape[1]\n",
    "        self.label_embedding = nn.Embedding(num_classes, self.input_dim)  # 將類別標籤轉換為與輸入數據相同維度的向量\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.input_dim * 2, hidden_dim * 8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim * 8, hidden_dim * 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim * 4, hidden_dim * 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        label_embedding = self.label_embedding(labels)\n",
    "        input_data = torch.cat([x.view(x.size(0), -1), label_embedding], dim=1)  # 將輸入數據與條件 labels 拼接\n",
    "        return self.model(input_data)\n",
    "\n",
    "\n",
    "# 假設原始MFCC矩陣的形狀為(13, 44)\n",
    "mfcc_shape = (13, 44)\n",
    "input_dim =  2048 # 生成器的輸入維度2048\n",
    "hidden_dim = 128\n",
    "num_classes = 1467\n",
    "\n",
    "# 初始化生成器和判別器\n",
    "generator = ConditionalGenerator(input_dim, hidden_dim, mfcc_shape, num_classes).to(device)\n",
    "discriminator = ConditionalDiscriminator(mfcc_shape, hidden_dim,num_classes).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.00000001)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.00000001)#0.0000001\n",
    "\n",
    "# 創建數據集和數據加載器\n",
    "dataset = PhonemeDataset(data, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 訓練GAN模型\n",
    "num_epochs = 1000\n",
    "d_steps = 1  # 每個生成器步驟後訓練判別器的步數\n",
    "g_steps = 3  # 每個判別器步驟後訓練生成器的步數\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, labels) in enumerate(dataloader):\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)  # 標籤同樣移動到設備上\n",
    "        batch_size = data.size(0)\n",
    "\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # 訓練判別器\n",
    "        for _ in range(d_steps):\n",
    "            outputs = discriminator(data, labels)  # 輸入數據和對應的標籤\n",
    "            d_loss_real = criterion(outputs, real_labels)\n",
    "            real_score = outputs\n",
    "\n",
    "            z = torch.randn(batch_size, input_dim).to(device)\n",
    "            fake_data = generator(z, labels)  # 使用相同的標籤生成數據\n",
    "            outputs = discriminator(fake_data.detach(), labels)\n",
    "            d_loss_fake = criterion(outputs, fake_labels)\n",
    "            fake_score = outputs\n",
    "\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            optimizer_D.zero_grad()\n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "        # 訓練生成器\n",
    "        for _ in range(g_steps):\n",
    "            z = torch.randn(batch_size, input_dim).to(device)\n",
    "            fake_data = generator(z, labels)  # 使用相同的標籤生成數據\n",
    "            outputs = discriminator(fake_data, labels)\n",
    "            g_loss = criterion(outputs, real_labels)\n",
    "\n",
    "            optimizer_G.zero_grad()\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}, '\n",
    "          f'D(x): {real_score.mean().item():.2f}, D(G(z)): {fake_score.mean().item():.2f}')\n",
    "\n",
    "    every_epoch.append(epoch)\n",
    "    every_d_loss.append(d_loss.item())\n",
    "    every_g_loss.append(g_loss.item())\n",
    "    every_DZ.append(fake_score.mean().item())\n",
    "\n",
    "\n",
    "print('訓練完成！')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), 'cGAN_generator_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(every_epoch,  every_d_loss, linestyle='-', label='Discriminator Loss')\n",
    "plt.plot(every_epoch,  every_g_loss, linestyle='-', label='Generator Loss')\n",
    "plt.title(f'在{data_len}筆資料和{num_epochs}次epoch下d_loss與g_loss的變化')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('d_loss')\n",
    "\n",
    "\n",
    "plt.legend() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.tensor([0] * batch_size).to(device)  # 生成標籤為 10 的資料\n",
    "fake_data = generator(z, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3963e-01, -5.7526e-02, -2.8917e-01, -3.1526e-01, -1.8496e-01,\n",
       "         -3.4675e-01, -1.9888e-01,  2.3545e-01,  3.9849e-03,  1.2673e-01,\n",
       "         -1.5811e-01, -4.6341e-01, -2.8550e-01,  1.4929e-01,  3.3220e-01,\n",
       "          1.0852e-01,  5.6662e-01, -2.0889e-03,  1.8429e-01, -2.9890e-01,\n",
       "          1.3085e-01,  4.1196e-01,  1.4706e-01, -2.5638e-01,  1.0131e-01,\n",
       "         -2.5130e-01, -8.4573e-02, -1.6859e-01, -3.0813e-02, -1.7142e-01,\n",
       "         -2.0911e-01, -4.6694e-01, -2.0568e-01, -2.7094e-01,  4.1624e-01,\n",
       "         -1.7050e-01, -1.4946e-01, -4.4927e-01,  3.7958e-03,  4.7488e-01,\n",
       "          1.0045e-01,  1.7025e-02,  8.6403e-02, -2.4957e-01],\n",
       "        [ 7.0983e-01, -2.9282e-01, -1.7517e-02,  1.3027e-01, -3.8194e-01,\n",
       "          1.6583e-01,  5.0898e-01, -4.6685e-01, -1.7820e-01,  3.2912e-01,\n",
       "         -1.9394e-01, -1.2638e-01,  3.1791e-01,  2.7253e-01,  4.4557e-02,\n",
       "          1.0657e-01, -2.3042e-01,  4.0665e-01,  9.8876e-02, -9.9301e-02,\n",
       "         -1.3348e-01,  3.7261e-01, -1.0361e-01,  5.0852e-01,  6.6074e-01,\n",
       "         -4.1053e-02,  4.9937e-01, -2.3840e-01,  1.3333e-01,  2.1118e-01,\n",
       "         -8.1985e-01,  2.0384e-01,  1.8161e-01,  6.1320e-01,  3.4529e-01,\n",
       "         -5.2048e-01,  3.6322e-01, -2.1605e-01,  1.0020e-01, -1.2539e-01,\n",
       "          6.6146e-02,  3.5339e-01,  3.1359e-01, -2.7343e-01],\n",
       "        [ 7.6488e-01,  3.3730e-01, -4.3822e-01, -4.3486e-01, -6.5219e-01,\n",
       "         -2.0695e-01,  3.6243e-01, -3.4242e-01,  4.6827e-02, -5.8428e-01,\n",
       "         -5.3212e-01,  1.9793e-01,  5.4639e-02, -1.2484e-01,  1.1086e-01,\n",
       "          3.5154e-01, -1.2808e-01,  1.2425e-01,  1.9294e-01,  6.2406e-02,\n",
       "         -4.4421e-01, -5.3152e-01, -1.4671e-01,  2.2848e-01, -5.1123e-01,\n",
       "         -1.5598e-01,  3.1564e-01, -3.0362e-01,  3.4412e-01, -4.4596e-01,\n",
       "         -2.4187e-01, -6.3070e-01,  4.7850e-01, -3.0345e-01,  4.6546e-01,\n",
       "          1.6430e-01,  1.7476e-01, -4.4406e-02, -6.7765e-03,  2.5653e-01,\n",
       "         -2.6569e-02,  4.2125e-01,  2.7468e-01,  2.0522e-01],\n",
       "        [-1.4421e-01,  1.1997e-01, -1.5916e-01,  6.9634e-01,  4.3288e-01,\n",
       "         -5.7160e-01, -1.6473e-02,  2.0361e-01, -1.0956e-01,  4.3011e-01,\n",
       "         -3.7637e-01, -3.5362e-01, -4.8055e-01, -3.8362e-01,  1.1240e-01,\n",
       "          2.9669e-01,  2.5277e-01, -5.3291e-01, -2.6706e-02,  4.4952e-01,\n",
       "         -2.6084e-01,  8.0798e-02, -8.0018e-03,  1.0918e-01,  3.1461e-01,\n",
       "          3.1468e-01, -6.3892e-01,  4.9915e-01, -7.6079e-01,  4.3372e-01,\n",
       "         -1.2601e-01,  2.4502e-01,  2.8549e-01, -4.0283e-01,  2.7351e-01,\n",
       "         -4.8117e-01,  3.3881e-02,  4.5327e-01,  5.2288e-02,  2.7566e-01,\n",
       "          5.1129e-02,  1.5498e-01,  2.1564e-02, -1.6120e-01],\n",
       "        [ 1.9872e-01, -6.5662e-01, -7.5812e-02,  1.8898e-02,  2.5692e-01,\n",
       "          3.2932e-01,  3.2220e-01, -4.4009e-01, -7.1720e-02,  1.7793e-01,\n",
       "          5.4029e-01, -2.2280e-01,  2.6822e-01,  2.5221e-01,  5.8737e-01,\n",
       "          1.7078e-02,  3.0737e-01, -1.5802e-01, -4.9456e-01, -9.8743e-02,\n",
       "         -2.1001e-01,  2.4218e-01, -3.6966e-01, -5.7165e-03,  4.9985e-01,\n",
       "          1.8868e-01,  3.6936e-01, -2.4024e-01, -5.2887e-01,  6.7116e-01,\n",
       "          1.3109e-01,  1.5687e-02, -3.2887e-01, -3.8638e-02,  1.3015e-01,\n",
       "         -2.4211e-01,  5.0141e-01,  2.9699e-01,  1.5257e-01,  7.6368e-01,\n",
       "          3.3585e-01, -3.0160e-01, -3.1983e-01,  2.2968e-01],\n",
       "        [ 2.5614e-01,  1.1428e-01,  7.1673e-02,  2.5427e-01,  2.7666e-01,\n",
       "          1.5895e-01,  8.9055e-02,  5.7534e-01, -3.8854e-01, -2.1353e-01,\n",
       "         -9.0189e-02,  2.3889e-01,  4.5774e-01, -4.8571e-01,  9.9418e-02,\n",
       "         -6.7369e-01, -2.3078e-01, -2.4869e-01, -3.3242e-01, -5.6393e-01,\n",
       "          5.2569e-01,  1.1147e-02, -3.4940e-01,  4.7304e-01,  2.6399e-01,\n",
       "          5.3658e-01, -6.4275e-01,  3.3411e-01,  2.3671e-01, -1.6836e-01,\n",
       "         -1.3656e-01,  3.7179e-01, -6.5546e-02,  5.5980e-01, -1.4573e-01,\n",
       "         -3.6662e-01, -5.3912e-01, -3.0951e-01,  7.0118e-01, -1.3208e-01,\n",
       "          9.8996e-02, -1.2034e-01,  2.6629e-03,  4.3124e-01],\n",
       "        [ 7.9528e-02, -1.7928e-01, -1.2802e-01,  1.9147e-01,  6.8040e-02,\n",
       "          3.7188e-01,  6.3122e-01,  5.9710e-01, -3.9320e-02,  1.1196e-01,\n",
       "          3.5416e-02,  1.2888e-02,  1.6098e-01, -4.1020e-02,  1.7849e-01,\n",
       "         -2.6405e-02,  3.7201e-02,  5.5501e-01, -5.2078e-02, -7.0557e-01,\n",
       "          2.4425e-01,  2.5876e-01, -4.6850e-01,  3.4647e-01, -4.0861e-01,\n",
       "         -3.4302e-01, -2.7753e-01,  2.2401e-01,  1.8795e-01,  2.1340e-01,\n",
       "         -4.6048e-02,  3.6843e-01,  4.8743e-01, -3.8773e-02, -3.7003e-02,\n",
       "          5.9269e-02,  3.9896e-01,  7.0455e-02, -2.3957e-01, -4.6007e-01,\n",
       "         -2.2353e-01,  7.4592e-03,  1.4107e-02,  4.1540e-01],\n",
       "        [ 2.3361e-01, -2.2254e-02, -6.1093e-02,  3.6805e-01,  5.5135e-01,\n",
       "         -1.0077e-01, -3.2595e-01,  3.5711e-01,  3.6259e-01, -3.1098e-02,\n",
       "         -1.0605e-01,  1.5525e-01,  2.2047e-01, -3.8170e-02,  3.7853e-01,\n",
       "         -3.1428e-01, -3.4926e-01,  2.4645e-01,  2.0370e-02,  2.8058e-01,\n",
       "          1.3193e-01, -2.5206e-01,  9.9073e-02, -3.8355e-01,  2.6032e-02,\n",
       "         -3.4310e-01, -1.1291e-01,  1.6006e-01,  1.7542e-01, -1.9909e-01,\n",
       "         -4.4918e-01, -1.3340e-01,  1.1574e-03,  1.3858e-01, -2.8944e-01,\n",
       "         -4.1726e-01,  3.2147e-01, -4.0617e-01, -1.9077e-01, -4.8956e-01,\n",
       "          1.2783e-01,  3.5439e-01,  1.5658e-01,  3.5447e-02],\n",
       "        [-6.7086e-01,  1.0202e-01, -9.3209e-02,  1.1358e-01, -5.3444e-01,\n",
       "         -2.8974e-01, -2.0248e-02, -1.8005e-01,  3.2190e-02, -3.8770e-01,\n",
       "          4.8362e-01,  2.5598e-01,  3.7807e-01,  2.2225e-01, -5.7321e-01,\n",
       "         -3.3536e-01, -4.3858e-01,  5.9647e-01, -7.0882e-01, -2.9402e-01,\n",
       "         -8.9404e-02,  2.2943e-01,  2.5890e-01,  2.5801e-02, -1.0809e-01,\n",
       "          1.7033e-02, -3.1441e-01,  2.8205e-02, -2.8826e-01,  2.6036e-01,\n",
       "         -2.5612e-01, -2.2077e-01,  1.8907e-01, -7.2722e-01, -4.5150e-01,\n",
       "          1.5311e-02,  3.5978e-01,  1.1415e-01,  2.3286e-01,  1.1196e-01,\n",
       "          3.6407e-01, -2.4912e-01,  6.8643e-02,  3.6514e-01],\n",
       "        [ 5.5671e-01, -4.0837e-01,  6.5092e-01, -4.4867e-01,  2.8508e-01,\n",
       "         -4.9849e-01, -1.1745e-01, -7.2177e-01, -3.2161e-01,  2.3968e-01,\n",
       "         -1.3628e-01, -7.1604e-01,  2.5582e-01,  2.9609e-01,  4.0379e-01,\n",
       "         -3.7940e-01, -4.9921e-01,  3.1161e-01, -4.0985e-01,  1.7318e-01,\n",
       "          1.3165e-01,  3.3888e-01, -1.5749e-01, -5.3270e-01,  2.0503e-01,\n",
       "         -6.6015e-01, -1.7808e-01,  4.8841e-02, -8.0284e-02, -3.9255e-01,\n",
       "          3.4036e-01,  3.8157e-01, -2.8377e-01,  4.5698e-01,  2.3303e-01,\n",
       "         -1.1247e-01, -2.7250e-01, -1.7400e-02, -1.6401e-01, -4.9540e-01,\n",
       "          1.0895e-01, -3.8820e-01, -1.4247e-01,  2.5099e-01],\n",
       "        [ 1.6895e-01, -3.6848e-01, -1.4013e-01, -2.6396e-01, -1.5415e-01,\n",
       "         -2.7749e-01,  7.1816e-01,  2.3688e-01, -3.8206e-01, -6.8164e-01,\n",
       "         -1.0102e-01,  3.6153e-02,  1.2341e-01,  6.2014e-02, -6.6023e-01,\n",
       "         -3.2990e-01, -1.1416e-01,  7.2316e-01, -1.8787e-01,  4.7007e-02,\n",
       "         -6.7090e-01,  2.9409e-01, -1.5379e-02, -9.7541e-02, -6.7760e-01,\n",
       "         -7.7365e-02,  1.9521e-01,  4.3700e-01,  1.9887e-01, -3.8611e-01,\n",
       "          1.3022e-01,  7.0311e-01, -1.2281e-01,  2.4837e-01, -1.7485e-01,\n",
       "         -2.3092e-01, -1.5530e-01,  1.5676e-01,  5.1411e-01, -1.4108e-01,\n",
       "          2.7241e-01,  8.4362e-02,  4.7387e-02, -1.7322e-01],\n",
       "        [ 3.5163e-01, -2.4637e-01, -4.4731e-01,  1.9476e-01,  7.0730e-02,\n",
       "         -3.3201e-01, -4.7735e-01,  2.8568e-01,  2.7967e-02, -2.7484e-01,\n",
       "         -3.8822e-01, -1.6493e-01, -1.2641e-01,  3.1394e-01,  2.5222e-01,\n",
       "          5.5098e-01,  1.9679e-01,  5.5203e-02, -3.1884e-01,  4.1674e-01,\n",
       "         -1.2430e-02, -1.1487e-01,  7.6209e-01, -7.6358e-02, -1.8012e-01,\n",
       "         -4.9291e-02,  2.7541e-05, -3.8860e-01,  5.1555e-01, -6.4364e-01,\n",
       "         -3.8876e-01,  2.2690e-01,  3.7716e-01,  5.9096e-01,  7.6621e-02,\n",
       "         -6.5049e-01,  4.1365e-01, -7.4425e-01, -4.7956e-01, -2.5005e-01,\n",
       "          4.1684e-02,  4.9308e-01,  3.1024e-01,  3.3814e-01],\n",
       "        [ 3.9853e-01, -2.8917e-01,  2.5831e-01, -5.3153e-01,  1.6240e-02,\n",
       "         -1.8322e-01,  1.0763e-02, -5.7075e-01, -3.8401e-02,  5.8006e-02,\n",
       "          6.0765e-01, -2.0808e-01,  5.8127e-01,  1.5403e-02,  4.1507e-01,\n",
       "          2.8734e-01,  2.7675e-01, -1.1777e-02,  1.3335e-02,  2.9442e-01,\n",
       "          1.1185e-01,  8.4675e-02, -5.5088e-01,  4.2116e-01,  1.8889e-01,\n",
       "          5.2447e-01,  2.4109e-01, -2.1417e-01, -2.1647e-01, -1.7323e-02,\n",
       "         -5.5277e-01, -2.1171e-01, -3.8607e-01, -1.1648e-01,  3.2462e-01,\n",
       "          4.6074e-01, -3.7848e-01, -4.9757e-01,  8.6942e-02, -3.6239e-01,\n",
       "         -1.9509e-01,  1.9318e-01, -6.2529e-02, -2.9732e-01]], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_data[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
