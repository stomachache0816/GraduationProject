{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import platform\n",
    "print(f\"platform.python_version(): {platform.python_version()}\")\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rc('font', family='Microsoft JhengHei')\n",
    "\n",
    "import requests\n",
    "\n",
    "# 檢查CUDA是否可用\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "#######################################################################\n",
    "#載入mfcc為data\n",
    "npy_file_list = glob(f\"..\\\\data\\\\mfccEduVer\\\\*.npy\")\n",
    "print(f\"type(npy_file_list): {type(npy_file_list)}\")\n",
    "print(f\"len(npy_file_list): {len(npy_file_list)}\")\n",
    "\n",
    "mfcc_list = []\n",
    "\n",
    "for npy_file in tqdm(npy_file_list):\n",
    "    mfcc = np.load(file=npy_file)\n",
    "    mfcc_list.append(mfcc)\n",
    "\n",
    "mfcc_list = np.array(mfcc_list)\n",
    "print(f\"type(mfcc_list): {type(mfcc_list)}\")\n",
    "print(f\"mfcc_list.shape: {mfcc_list.shape}\")\n",
    "\n",
    "all_mfcc = []\n",
    "for mfcc in mfcc_list:\n",
    "    all_mfcc.append(mfcc)\n",
    "\n",
    "data = np.array(all_mfcc)\n",
    "data_len = len(data)\n",
    "#######################################################################\n",
    "\n",
    "#######################################################################\n",
    "#載入labelByself為labels\n",
    "load_data = np.load(f\".\\\\labelByself.npz\")\n",
    "labels = load_data['data']\n",
    "#######################################################################\n",
    "\n",
    "every_epoch = [] \n",
    "every_d_loss = []\n",
    "every_g_loss = []\n",
    "every_DZ = []\n",
    "\n",
    "class PhonemeDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "class ConditionalGenerator(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_shape, num_classes):\n",
    "        super(ConditionalGenerator, self).__init__()\n",
    "        self.output_shape = output_shape\n",
    "        self.output_dim = output_shape[0] * output_shape[1]\n",
    "        self.label_embedding = nn.Embedding(num_classes, input_dim)  # 將類別標籤轉換為與 z 相同維度的向量\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim * 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "            nn.BatchNorm1d(hidden_dim * 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim * 4), \n",
    "            nn.BatchNorm1d(hidden_dim * 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim * 4, self.output_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z, labels):\n",
    "        label_embedding = self.label_embedding(labels)\n",
    "        input_data = torch.cat([z, label_embedding], dim=1)  # 將噪聲 z 與條件 labels 拼接\n",
    "        x = self.model(input_data)\n",
    "        return x.view(x.size(0), *self.output_shape)\n",
    "\n",
    "\n",
    "class ConditionalDiscriminator(nn.Module):\n",
    "    def __init__(self, input_shape, hidden_dim, num_classes):\n",
    "        super(ConditionalDiscriminator, self).__init__()\n",
    "        self.input_dim = input_shape[0] * input_shape[1]\n",
    "        self.label_embedding = nn.Embedding(num_classes, self.input_dim)  # 將類別標籤轉換為與輸入數據相同維度的向量\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.input_dim * 2, hidden_dim * 8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim * 8, hidden_dim * 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim * 4, hidden_dim * 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        label_embedding = self.label_embedding(labels)\n",
    "        input_data = torch.cat([x.view(x.size(0), -1), label_embedding], dim=1)  # 將輸入數據與條件 labels 拼接\n",
    "        return self.model(input_data)\n",
    "\n",
    "def get_max_batch_size(model, input_shape):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    max_memory = torch.cuda.get_device_properties(0).total_memory  \n",
    "    reserved_memory = torch.cuda.memory_reserved(0)  \n",
    "    free_memory = max_memory - reserved_memory  \n",
    "\n",
    "    # 計算每個樣本所需的記憶體（假設每個浮點數佔用4字節）\n",
    "    sample_size = (input_shape[0] * input_shape[1] + model.label_embedding.embedding_dim) * 4 + sum(p.numel() for p in model.parameters()) * 4\n",
    "\n",
    "    # 計算最大批量大小\n",
    "    max_batch_size = free_memory // sample_size if sample_size > 0 else 1\n",
    "    return max_batch_size\n",
    "\n",
    "# 超參數\n",
    "input_dim = 572  # 輸入數據的特徵數量13*44=572\n",
    "hidden_dim = 128 # input_dim的一半286\n",
    "generator_learning_rate = 0.00000001\n",
    "discriminator_learning_rate = 0.00000001\n",
    "num_epochs = 5000 # 訓練次數\n",
    "d_steps = 1  # 每個生成器步驟後訓練判別器的步數\n",
    "g_steps = 3  # 每個判別器步驟後訓練生成器的步數\n",
    "\n",
    "# 假設原始MFCC矩陣的形狀為(13, 44)\n",
    "mfcc_shape = (13, 44)\n",
    "num_classes = 1467\n",
    "\n",
    "# 初始化生成器和判別器\n",
    "generator = ConditionalGenerator(input_dim, hidden_dim, mfcc_shape, num_classes).to(device)\n",
    "discriminator = ConditionalDiscriminator(mfcc_shape, hidden_dim, num_classes).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr = generator_learning_rate)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr= discriminator_learning_rate)\n",
    "\n",
    "scheduler_G = optim.lr_scheduler.StepLR(optimizer_G, step_size=500, gamma=0.5) # 每1000步將學習率減半\n",
    "scheduler_D = optim.lr_scheduler.StepLR(optimizer_D, step_size=1000, gamma=0.5) # 每1000步將學習率減半\n",
    "\n",
    "# 計算最大批量大小並創建數據集和數據加載器\n",
    "max_batch_size = get_max_batch_size(discriminator, mfcc_shape)\n",
    "print(f'Maximum batch size that can be used: {max_batch_size}')\n",
    "\n",
    "# 創建數據集和數據加載器\n",
    "dataset = PhonemeDataset(data, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=max_batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, labels) in enumerate(dataloader):\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)  # 標籤同樣移動到設備上\n",
    "        batch_size = data.size(0)\n",
    "\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # 訓練判別器\n",
    "        for _ in range(d_steps):\n",
    "            outputs = discriminator(data, labels)  # 輸入數據和對應的標籤\n",
    "            d_loss_real = criterion(outputs, real_labels)\n",
    "            real_score = outputs\n",
    "\n",
    "            z = torch.randn(batch_size, input_dim).to(device)\n",
    "            fake_data = generator(z, labels)  # 使用相同的標籤生成數據\n",
    "            outputs = discriminator(fake_data.detach(), labels)\n",
    "            d_loss_fake = criterion(outputs, fake_labels)\n",
    "            fake_score = outputs\n",
    "\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            optimizer_D.zero_grad()\n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "        # 訓練生成器\n",
    "        for _ in range(g_steps):\n",
    "            z = torch.randn(batch_size, input_dim).to(device)\n",
    "            fake_data = generator(z, labels)  # 使用相同的標籤生成數據\n",
    "            outputs = discriminator(fake_data, labels)\n",
    "            g_loss = criterion(outputs, real_labels)\n",
    "\n",
    "            optimizer_G.zero_grad()\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "    # 更新學習率調度器\n",
    "    scheduler_G.step()\n",
    "    scheduler_D.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}, '\n",
    "          f'D(x): {real_score.mean().item():.2f}, D(G(z)): {fake_score.mean().item():.2f}')\n",
    "\n",
    "    every_epoch.append(epoch)\n",
    "    every_d_loss.append(d_loss.item())\n",
    "    every_g_loss.append(g_loss.item())\n",
    "    every_DZ.append(fake_score.mean().item())\n",
    "\n",
    "\n",
    "print('訓練完成！')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# DISCORD -> 設定 -> 整合 -> Webhook -> 新 Webhook > -> 複製 Webhook 網址\n",
    "DISCORD_WEBHOOK_URL = \"https://discord.com/api/webhooks/1287413088970346557/30gx7NdIfSxS1BRWk28IRkOHJeoET-ihIN_KAjYeXYkrpPeI0hBnE-68AHzhpTR4h3et\"\n",
    "requests.post(\n",
    "    url=DISCORD_WEBHOOK_URL,\n",
    "    data={\"content\": \"cGan訓練已完成!\"}\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "torch.save(generator.state_dict(), f\".\\\\cGAN_generator_edu_model.pth\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.plot(every_epoch,  every_d_loss, linestyle='-', label='Discriminator Loss')\n",
    "plt.plot(every_epoch,  every_g_loss, linestyle='-', label='Generator Loss')\n",
    "plt.title(f'在{data_len}筆資料和{num_epochs}次epoch下d_loss與g_loss的變化')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('d_loss')\n",
    "\n",
    "\n",
    "plt.legend() \n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class ConditionalGenerator(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_shape, num_classes):\n",
    "        super(ConditionalGenerator, self).__init__()\n",
    "        self.output_shape = output_shape\n",
    "        self.output_dim = output_shape[0] * output_shape[1]\n",
    "        self.label_embedding = nn.Embedding(num_classes, input_dim)  # 將類別標籤轉換為與 z 相同維度的向量\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim * 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "            nn.BatchNorm1d(hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim * 4), \n",
    "            nn.BatchNorm1d(hidden_dim * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim * 4, self.output_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z, labels):\n",
    "        label_embedding = self.label_embedding(labels)\n",
    "        input_data = torch.cat([z, label_embedding], dim=1)  # 將噪聲 z 與條件 labels 拼接\n",
    "        x = self.model(input_data)\n",
    "        return x.view(x.size(0), *self.output_shape)\n",
    "    \n",
    "# 參數\n",
    "input_dim =  2048 \n",
    "hidden_dim = 128\n",
    "mfcc_shape = (13, 44)\n",
    "num_classes = 1467\n",
    "\n",
    "# 初始化生成器\n",
    "generator = ConditionalGenerator(input_dim, hidden_dim, mfcc_shape, num_classes).to(device)\n",
    "# 載入儲存的生成器權重\n",
    "# generator.load_state_dict(torch.load(f\".\\\\cGAN_generator_model.pth\"))\n",
    "generator.load_state_dict(torch.load(f\".\\\\cGAN_generator_edu_model.pth\", weights_only=True), strict=False)\n",
    "# 確保模型設定為評估模式\n",
    "generator.eval()\n",
    "\n",
    "batch_size = 100\n",
    "z = torch.randn(batch_size, input_dim).to(device)\n",
    "\n",
    "labels = torch.tensor([10] * batch_size).to(device)  # 生成標籤為 10 的資料\n",
    "fake_data = generator(z, labels)\n",
    "\n",
    "print('確認單筆資料為',len(fake_data[0]),'x',len(fake_data[0][0]),'與預計輸出為 13x14')\n",
    "print('一次生成',len(fake_data),'個 fake data')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fake_data[0]"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
